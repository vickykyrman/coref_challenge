{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import checklist\n",
    "from checklist.editor import Editor\n",
    "editor = Editor()\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "#np.random.seed(42)\n",
    "#random.seed(42)\n",
    "\n",
    "# #from wonderwords import RandomWord, RandomSentence\n",
    "# word_generator = RandomWord()\n",
    "# sent_generator = RandomSentence()\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_noise_male_bias = {'male_referent':[], 'female_referent':[], 'anaphor_type':[], 'male_gold':[], 'female_gold':[]}  #simple version\n",
    "no_noise_female_bias = {'male_referent':[], 'female_referent':[], 'anaphor_type':[], 'male_gold':[], 'female_gold':[]} #simple version\n",
    "\n",
    "noise_male_bias = {'male_referent':[], 'female_referent':[], 'anaphor_type':[], 'male_gold':[], 'female_gold':[]}  #extra pronoun disambiguation challenge (semantic capability)\n",
    "noise_female_bias = {'male_referent':[], 'female_referent':[], 'anaphor_type':[], 'male_gold':[], 'female_gold':[]} #extra disambiguation challenge\n",
    "#The firefighter saved the man with the support of his team\n",
    "#The firefighter saved the woman with the support of her team    #If it manages to solve the correference by also handling the ambiguity in the male (expected) version and it has to do so in the female version as well\n",
    "gender_bias_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#male bias - no noise\n",
    "case1 = [('The MALE_BIAS ALIAS1 ALIAS2, but he ALIAS3.', 'The MALE_BIAS ALIAS1 ALIAS2, but she ALIAS3.'), #personal pronoun\n",
    "        ('The MALE_BIAS ALIAS1, and his ALIAS2 ALIAS3.', 'The MALE_BIAS ALIAS1, and her ALIAS2 ALIAS3.')] #possessive pronoun\n",
    "#female bias - no noise\n",
    "case2 = [('The FEMALE_BIAS ALIAS1 ALIAS2, but he ALIAS3.', 'The FEMALE_BIAS ALIAS1 ALIAS2, but she ALIAS3.'), #personal pronoun \n",
    "        ('The FEMALE_BIAS ALIAS1 ALIAS2, and his ALIAS3.', 'The FEMALE_BIAS ALIAS1 ALIAS2, and her ALIAS3.')] #possessive pronoun\n",
    "\n",
    "#male bias - noise\n",
    "case3 = [('The MALE_BIAS ALIAS1 MALE_NAME ALIAS2 with his ALIAS3.', 'The MALE_BIAS ALIAS1 FEMALE_NAME ALIAS2 with her ALIAS3.'), #possessive pronoun\n",
    "        ('The MALE_BIAS ALIAS1 MALE_NAME, and then he ALIAS2.', 'The MALE_BIAS ALIAS1 FEMALE_NAME, and then she ALIAS2.')] #personal pronoun\n",
    "#female bias - noise\n",
    "case4 = [('The FEMALE_BIAS ALIAS1 MALE_NAME ALIAS2 with his ALIAS3.', 'The FEMALE_BIAS ALIAS1 FEMALE_NAME ALIAS2 with her ALIAS3.'), #possessive pronoun\n",
    "        ('The FEMALE_BIAS ALIAS1 MALE_NAME, and then he ALIAS2.', 'The FEMALE_BIAS ALIAS1 FEMALE_NAME, and then she ALIAS2.')] #personal pronoun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_bias = ['doctor','soldier','president','pilot','farmer','chef','professor','officer','firefighter','lawyer','athlete','football player','astronaut','manager']\n",
    "female_bias = ['hairdresser','secretary','nanny','nurse','teacher','dancer','singer','shop assistant','cheerleader','escort','house keeper','model','make-up artist','cashier']\n",
    "\n",
    "male_names = editor.lexicons['male'][:20]\n",
    "female_names = editor.lexicons['female'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tried\n",
      "tries\n",
      "lost\n",
      "was\n",
      "seemed\n",
      "seemed\n",
      "was\n",
      "walked\n",
      "seemed\n",
      "was\n",
      "barely\n",
      "was\n",
      "seemed\n",
      "barely\n",
      "was\n",
      "was\n",
      "feared\n",
      "tried\n",
      "lost\n",
      "seemed\n",
      "could\n",
      "never\n",
      "looked\n",
      "looked\n",
      "seemed\n",
      "was\n",
      "looked\n",
      "said\n",
      "started\n",
      "tried\n",
      "seemed\n",
      "was\n",
      "walked\n",
      "seemed\n",
      "seemed\n",
      "almost\n",
      "was\n",
      "started\n",
      "was\n",
      "was\n",
      "started\n",
      "looked\n",
      "was\n",
      "was\n",
      "seemed\n",
      "denied\n",
      "fell\n",
      "seemed\n",
      "broke\n",
      "tries\n",
      "('seemed', 'surprised', 'agreed')\n",
      "('was', 'dying', 'survived')\n",
      "('seemed', 'nervous', 'nodded')\n",
      "was\n",
      "starts\n",
      "falls\n",
      "got\n",
      "starts\n",
      "is\n",
      "is\n",
      "falls\n",
      "was\n",
      "gets\n",
      "is\n",
      "was\n",
      "tries\n",
      "is\n",
      "fights\n",
      "was\n",
      "is\n",
      "tries\n",
      "falls\n",
      "got\n",
      "gets\n",
      "gets\n",
      "was\n",
      "is\n",
      "was\n",
      "starts\n",
      "starts\n",
      "is\n",
      "falls\n",
      "fights\n",
      "gets\n",
      "fell\n",
      "is\n",
      "is\n",
      "is\n",
      "runs\n",
      "steps\n",
      "falls\n",
      "fights\n",
      "falls\n",
      "steps\n",
      "starts\n",
      "was\n",
      "moves\n",
      "starts\n",
      "got\n",
      "fell\n",
      "starts\n",
      "fell\n",
      "loses\n",
      "('breaks', 'free', 'dies')\n",
      "('was', 'killed', 'escaped')\n",
      "('is', 'shot', 'escapes')\n",
      "tried\n",
      "should\n",
      "was\n",
      "was\n",
      "fought\n",
      "tries\n",
      "should\n",
      "fought\n",
      "could\n",
      "fought\n",
      "was\n",
      "was\n",
      "knows\n",
      "was\n",
      "should\n",
      "should\n",
      "was\n",
      "was\n",
      "tries\n",
      "tries\n",
      "was\n",
      "fought\n",
      "tried\n",
      "was\n",
      "knows\n",
      "should\n",
      "knows\n",
      "says\n",
      "was\n",
      "was\n",
      "was\n",
      "was\n",
      "was\n",
      "could\n",
      "was\n",
      "should\n",
      "was\n",
      "fought\n",
      "should\n",
      "says\n",
      "should\n",
      "knows\n",
      "was\n",
      "knew\n",
      "tries\n",
      "barely\n",
      "was\n",
      "knew\n",
      "was\n",
      "was\n",
      "('should', 'apologize', 'refuses')\n",
      "('was', 'defeated', 'survived')\n",
      "('was', 'disappointed', 'persisted')\n",
      "fires\n",
      "fell\n",
      "was\n",
      "lost\n",
      "gets\n",
      "is\n",
      "tries\n",
      "gave\n",
      "is\n",
      "is\n",
      "lost\n",
      "gave\n",
      "nearly\n",
      "loses\n",
      "gives\n",
      "lost\n",
      "nearly\n",
      "takes\n",
      "gives\n",
      "fights\n",
      "is\n",
      "takes\n",
      "was\n",
      "takes\n",
      "falls\n",
      "tries\n",
      "falls\n",
      "takes\n",
      "loses\n",
      "almost\n",
      "fights\n",
      "was\n",
      "was\n",
      "falls\n",
      "tries\n",
      "was\n",
      "pulled\n",
      "is\n",
      "fell\n",
      "is\n",
      "is\n",
      "is\n",
      "loses\n",
      "takes\n",
      "fell\n",
      "gives\n",
      "was\n",
      "takes\n",
      "looks\n",
      "gets\n",
      "('was', 'injured', 'escaped')\n",
      "('gets', 'shot', 'lives')\n",
      "('gave', 'chase', 'missed')\n",
      "falls\n",
      "falls\n",
      "falls\n",
      "fights\n",
      "is\n",
      "almost\n",
      "begs\n",
      "fights\n",
      "runs\n",
      "tries\n",
      "almost\n",
      "seems\n",
      "tells\n",
      "is\n",
      "is\n",
      "is\n",
      "stops\n",
      "gets\n",
      "falls\n",
      "seems\n",
      "looks\n",
      "ignored\n",
      "barely\n",
      "looks\n",
      "runs\n",
      "falls\n",
      "falls\n",
      "is\n",
      "seems\n",
      "is\n",
      "breaks\n",
      "seems\n",
      "is\n",
      "tries\n",
      "looks\n",
      "seems\n",
      "is\n",
      "looks\n",
      "is\n",
      "is\n",
      "looks\n",
      "falls\n",
      "was\n",
      "is\n",
      "was\n",
      "is\n",
      "walks\n",
      "looks\n",
      "was\n",
      "is\n",
      "('looks', 'nervous', 'smiles')\n",
      "('runs', 'away', 'notices')\n",
      "('runs', 'away', 'survives')\n",
      "tries\n",
      "almost\n",
      "fell\n",
      "fell\n",
      "told\n",
      "never\n",
      "seemed\n",
      "gave\n",
      "barely\n",
      "seems\n",
      "told\n",
      "falls\n",
      "fell\n",
      "walks\n",
      "barely\n",
      "falls\n",
      "was\n",
      "was\n",
      "seemed\n",
      "fell\n",
      "walks\n",
      "tries\n",
      "seemed\n",
      "looks\n",
      "fell\n",
      "seemed\n",
      "never\n",
      "seemed\n",
      "fell\n",
      "says\n",
      "says\n",
      "seems\n",
      "ignores\n",
      "seems\n",
      "walked\n",
      "looked\n",
      "seems\n",
      "seemed\n",
      "was\n",
      "tries\n",
      "seems\n",
      "barely\n",
      "is\n",
      "seemed\n",
      "seemed\n",
      "seemed\n",
      "barely\n",
      "looks\n",
      "falls\n",
      "tries\n",
      "('fell', 'apart', 'survived')\n",
      "('was', 'scared', 'persisted')\n",
      "('walks', 'away', 'stays')\n",
      "tried\n",
      "fell\n",
      "falls\n",
      "ignored\n",
      "was\n",
      "seemed\n",
      "fell\n",
      "walked\n",
      "was\n",
      "was\n",
      "looks\n",
      "is\n",
      "seemed\n",
      "walks\n",
      "was\n",
      "looks\n",
      "looked\n",
      "falls\n",
      "was\n",
      "seemed\n",
      "walked\n",
      "is\n",
      "seems\n",
      "looked\n",
      "seemed\n",
      "fell\n",
      "seemed\n",
      "fell\n",
      "tries\n",
      "started\n",
      "looks\n",
      "was\n",
      "falls\n",
      "was\n",
      "was\n",
      "says\n",
      "seemed\n",
      "seems\n",
      "seemed\n",
      "looks\n",
      "seemed\n",
      "seems\n",
      "tries\n",
      "said\n",
      "seemed\n",
      "looks\n",
      "runs\n",
      "was\n",
      "looks\n",
      "looks\n",
      "('looked', 'confused', 'persisted')\n",
      "('got', 'angry', 'left')\n",
      "('looks', 'skeptical', 'nods')\n",
      "fired\n",
      "fires\n",
      "was\n",
      "started\n",
      "got\n",
      "starts\n",
      "was\n",
      "falls\n",
      "gets\n",
      "loses\n",
      "was\n",
      "tried\n",
      "is\n",
      "fights\n",
      "tries\n",
      "fights\n",
      "fought\n",
      "falls\n",
      "was\n",
      "fought\n",
      "tried\n",
      "is\n",
      "fought\n",
      "was\n",
      "was\n",
      "shot\n",
      "is\n",
      "fired\n",
      "fires\n",
      "is\n",
      "fights\n",
      "fell\n",
      "got\n",
      "lost\n",
      "was\n",
      "was\n",
      "lost\n",
      "is\n",
      "started\n",
      "starts\n",
      "fired\n",
      "pulled\n",
      "gets\n",
      "gets\n",
      "fights\n",
      "was\n",
      "was\n",
      "runs\n",
      "started\n",
      "fell\n",
      "('is', 'shot', 'recovers')\n",
      "('is', 'injured', 'recovers')\n",
      "('tried', 'again', 'missed')\n",
      "was\n",
      "lost\n",
      "got\n",
      "was\n",
      "is\n",
      "was\n",
      "loses\n",
      "got\n",
      "gets\n",
      "falls\n",
      "fell\n",
      "tried\n",
      "was\n",
      "was\n",
      "was\n",
      "falls\n",
      "is\n",
      "fell\n",
      "fell\n",
      "was\n",
      "was\n",
      "was\n",
      "falls\n",
      "is\n",
      "falls\n",
      "was\n",
      "was\n",
      "fell\n",
      "lost\n",
      "was\n",
      "was\n",
      "was\n",
      "started\n",
      "gave\n",
      "lost\n",
      "was\n",
      "tried\n",
      "was\n",
      "was\n",
      "gets\n",
      "started\n",
      "is\n",
      "fell\n",
      "loses\n",
      "is\n",
      "gave\n",
      "was\n",
      "started\n",
      "was\n",
      "fell\n",
      "('was', 'shot', 'lived')\n",
      "('nearly', 'fell', 'survived')\n",
      "('was', 'hospitalized', 'survived')\n",
      "tried\n",
      "tried\n",
      "tried\n",
      "seemed\n",
      "was\n",
      "tried\n",
      "walked\n",
      "tried\n",
      "was\n",
      "fought\n",
      "walks\n",
      "tried\n",
      "tries\n",
      "was\n",
      "seemed\n",
      "seemed\n",
      "was\n",
      "fought\n",
      "seems\n",
      "looked\n",
      "walks\n",
      "could\n",
      "walked\n",
      "tries\n",
      "was\n",
      "was\n",
      "was\n",
      "kept\n",
      "tries\n",
      "tried\n",
      "pushed\n",
      "seemed\n",
      "was\n",
      "never\n",
      "was\n",
      "seemed\n",
      "was\n",
      "seemed\n",
      "looks\n",
      "says\n",
      "was\n",
      "kept\n",
      "tried\n",
      "was\n",
      "seemed\n",
      "seems\n",
      "looked\n",
      "was\n",
      "seemed\n",
      "seemed\n",
      "('gave', 'up', 'tried')\n",
      "('looked', 'nervous', 'understood')\n",
      "('gave', 'up', 'persisted')\n",
      "fell\n",
      "falls\n",
      "fell\n",
      "fell\n",
      "was\n",
      "falls\n",
      "got\n",
      "was\n",
      "tries\n",
      "feared\n",
      "knew\n",
      "was\n",
      "fell\n",
      "fought\n",
      "almost\n",
      "falls\n",
      "got\n",
      "fell\n",
      "fell\n",
      "fought\n",
      "feared\n",
      "fell\n",
      "falls\n",
      "fell\n",
      "tried\n",
      "fell\n",
      "fell\n",
      "lost\n",
      "fell\n",
      "never\n",
      "was\n",
      "fell\n",
      "falls\n",
      "fell\n",
      "falls\n",
      "gave\n",
      "fell\n",
      "tries\n",
      "fell\n",
      "knows\n",
      "never\n",
      "was\n",
      "falls\n",
      "was\n",
      "fell\n",
      "fell\n",
      "fell\n",
      "tries\n",
      "was\n",
      "fell\n",
      "('fell', 'backward', 'continued')\n",
      "('falls', 'back', 'survives')\n",
      "('fell', 'backward', 'recovered')\n",
      "fell\n",
      "falls\n",
      "fell\n",
      "was\n",
      "falls\n",
      "gets\n",
      "fought\n",
      "fights\n",
      "fell\n",
      "lost\n",
      "fought\n",
      "tries\n",
      "fell\n",
      "fell\n",
      "falls\n",
      "fought\n",
      "gets\n",
      "fights\n",
      "falls\n",
      "was\n",
      "gets\n",
      "fell\n",
      "fights\n",
      "fell\n",
      "fought\n",
      "walked\n",
      "fights\n",
      "fell\n",
      "gave\n",
      "falls\n",
      "falls\n",
      "falls\n",
      "was\n",
      "was\n",
      "walked\n",
      "fell\n",
      "was\n",
      "gets\n",
      "fights\n",
      "falls\n",
      "was\n",
      "falls\n",
      "was\n",
      "gets\n",
      "tried\n",
      "was\n",
      "knows\n",
      "died\n",
      "gets\n",
      "never\n",
      "('fell', 'unconscious', 'persisted')\n",
      "('falls', 'unconscious', 'survived')\n",
      "('walked', 'away', 'stayed')\n",
      "loses\n",
      "lost\n",
      "was\n",
      "was\n",
      "was\n",
      "is\n",
      "tried\n",
      "is\n",
      "falls\n",
      "is\n",
      "falls\n",
      "is\n",
      "falls\n",
      "fell\n",
      "is\n",
      "falls\n",
      "gets\n",
      "lost\n",
      "falls\n",
      "is\n",
      "wakes\n",
      "breaks\n",
      "falls\n",
      "loses\n",
      "lost\n",
      "starts\n",
      "falls\n",
      "runs\n",
      "almost\n",
      "gets\n",
      "runs\n",
      "was\n",
      "loses\n",
      "runs\n",
      "tries\n",
      "fell\n",
      "almost\n",
      "falls\n",
      "falls\n",
      "tries\n",
      "falls\n",
      "was\n",
      "is\n",
      "almost\n",
      "takes\n",
      "is\n",
      "was\n",
      "gets\n",
      "gets\n",
      "falls\n",
      "('falls', 'down', 'recovers')\n",
      "('loses', 'consciousness', 'remains')\n",
      "('is', 'killed', 'survives')\n",
      "tried\n",
      "was\n",
      "was\n",
      "was\n",
      "seems\n",
      "was\n",
      "was\n",
      "seems\n",
      "seems\n",
      "got\n",
      "was\n",
      "broke\n",
      "was\n",
      "seemed\n",
      "tried\n",
      "was\n",
      "felt\n",
      "seemed\n",
      "was\n",
      "looks\n",
      "said\n",
      "gets\n",
      "seemed\n",
      "looks\n",
      "was\n",
      "tries\n",
      "was\n",
      "was\n",
      "got\n",
      "was\n",
      "was\n",
      "was\n",
      "seemed\n",
      "was\n",
      "is\n",
      "was\n",
      "broke\n",
      "seemed\n",
      "says\n",
      "was\n",
      "looks\n",
      "looks\n",
      "tried\n",
      "walks\n",
      "tries\n",
      "seems\n",
      "was\n",
      "was\n",
      "knows\n",
      "seemed\n",
      "('seems', 'relieved', 'leaves')\n",
      "('looked', 'nervous', 'nodded')\n",
      "('was', 'angry', 'persisted')\n"
     ]
    }
   ],
   "source": [
    "#case1\n",
    "sent1 = case1[0][0] #male referent  PER PRON\n",
    "sent2 = case1[0][1] #female referent  PER PRON\n",
    "sent3 = case1[1][0] #male referent POS PRON\n",
    "sent4 = case1[1][1] #female referent POS PRON\n",
    "for i in male_bias:\n",
    "    new_sent = sent1.replace('MALE_BIAS',i)\n",
    "    #PER PRON\n",
    "    masked_sent = new_sent.replace('ALIAS1','{mask}').replace('ALIAS2','{mask}').replace('ALIAS3','{mask}')\n",
    "    alts = editor.suggest(masked_sent, remove_duplicates = True)[:100]\n",
    "    \n",
    "    for group in alts:\n",
    "        doc = nlp(group[0])\n",
    "        for token in doc:\n",
    "            print(token)\n",
    "            if token.pos_ != 'VERB':\n",
    "                break\n",
    "        alts.remove(group)\n",
    "        continue\n",
    "    random_nums = np.random.choice(len(alts),3)\n",
    "    for num in random_nums:\n",
    "        group = alts[num]\n",
    "        print(group)\n",
    "        male_sent = sent1.replace('MALE_BIAS',i).replace('ALIAS1',group[0]).replace('ALIAS2',group[1]).replace('ALIAS3',group[2])\n",
    "        female_sent = sent2.replace('MALE_BIAS',i).replace('ALIAS1',group[0]).replace('ALIAS2',group[1]).replace('ALIAS3',group[2])\n",
    "        no_noise_male_bias['male_referent'].append(male_sent)\n",
    "        no_noise_male_bias['female_referent'].append(female_sent)\n",
    "        no_noise_male_bias['anaphor_type'].append('PER_PRON')\n",
    "        no_noise_male_bias['male_gold'].append('The '+i+',he')\n",
    "        no_noise_male_bias['female_gold'].append('The '+i+',she')\n",
    "    \n",
    "    #POS PRON\n",
    "    new_sent = sent3.replace('MALE_BIAS',i)\n",
    "    masked2_sent = new_sent.replace('ALIAS1','{mask}').replace('ALIAS2','{mask}').replace('ALIAS3','{mask}')\n",
    "    alts = editor.suggest(masked2_sent, remove_duplicates = True)[:100]\n",
    "    for group in alts:\n",
    "        doc = nlp(group[0])\n",
    "        for token in doc:\n",
    "            if token.pos_ != 'VERB':\n",
    "                break\n",
    "        alts.remove(group)\n",
    "        continue\n",
    "    \n",
    "    random_nums = np.random.choice(len(alts),3)\n",
    "    for num in random_nums:\n",
    "        group = alts[num]\n",
    "        male_sent = sent3.replace('MALE_BIAS',i).replace('ALIAS1',group[0]).replace('ALIAS2',group[1]).replace('ALIAS3',group[2])\n",
    "        female_sent = sent4.replace('MALE_BIAS',i).replace('ALIAS1',group[0]).replace('ALIAS2',group[1]).replace('ALIAS3',group[2])\n",
    "        no_noise_male_bias['male_referent'].append(male_sent)\n",
    "        no_noise_male_bias['female_referent'].append(female_sent)\n",
    "        no_noise_male_bias['anaphor_type'].append('POS_PRON')\n",
    "        no_noise_male_bias['male_gold'].append('The '+i+',his')\n",
    "        no_noise_male_bias['female_gold'].append('The '+i+',her')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_noise_male_bias_df = pd.DataFrame.from_dict(no_noise_male_bias)\n",
    "bias = ['male']* len(no_noise_male_bias_df)\n",
    "no_noise_male_bias_df['gender_bias']=bias\n",
    "ambiguity = ['0'] * len(no_noise_male_bias_df)\n",
    "no_noise_male_bias_df['ambiguity']=ambiguity\n",
    "len(no_noise_male_bias_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#case2\n",
    "sent1 = case2[0][0] #male referent  PER PRON\n",
    "sent2 = case2[0][1] #female referent  PER PRON\n",
    "sent3 = case2[1][0] #male referent POS PRON\n",
    "sent4 = case2[1][1] #female referent POS PRON\n",
    "for i in female_bias:\n",
    "    #PER PRON\n",
    "    new_sent = sent1.replace('MALE_BIAS',i)\n",
    "    masked_sent = new_sent.replace('ALIAS1','{mask}').replace('ALIAS2','{mask}').replace('ALIAS3','{mask}')\n",
    "    alts = editor.suggest(masked_sent, remove_duplicates = True)[:100]\n",
    "    for group in alts:\n",
    "        doc = nlp(group[0])\n",
    "        for token in doc:\n",
    "            if token.pos_ != 'VERB':\n",
    "                break\n",
    "        alts.remove(group)\n",
    "        continue\n",
    "    random_nums = np.random.choice(len(alts),3)\n",
    "    for num in random_nums:\n",
    "        group = alts[num]\n",
    "        male_sent = sent1.replace('FEMALE_BIAS',i).replace('ALIAS1',group[0]).replace('ALIAS2',group[1]).replace('ALIAS3',group[2])\n",
    "        female_sent = sent2.replace('FEMALE_BIAS',i).replace('ALIAS1',group[0]).replace('ALIAS2',group[1]).replace('ALIAS3',group[2])\n",
    "        no_noise_female_bias['male_referent'].append(male_sent)\n",
    "        no_noise_female_bias['female_referent'].append(female_sent)\n",
    "        no_noise_female_bias['anaphor_type'].append('PER_PRON')\n",
    "        no_noise_female_bias['male_gold'].append('The '+i+',he')\n",
    "        no_noise_female_bias['female_gold'].append('The '+i+',she')\n",
    "    \n",
    "    #POS PRON\n",
    "    new_sent = sent3.replace('MALE_BIAS',i)\n",
    "    masked2_sent = new_sent.replace('ALIAS1','{mask}').replace('ALIAS2','{mask}').replace('ALIAS3','{mask}')\n",
    "    alts = editor.suggest(masked2_sent, remove_duplicates = True)[:100]\n",
    "    for group in alts:\n",
    "        doc = nlp(group[0])\n",
    "        for token in doc:\n",
    "            if token.pos_ != 'VERB':\n",
    "                break\n",
    "        alts.remove(group)\n",
    "        continue\n",
    "    random_nums = np.random.choice(len(alts),3)\n",
    "    for num in random_nums:\n",
    "        group = alts[num]\n",
    "        male_sent = sent3.replace('FEMALE_BIAS',i).replace('ALIAS1',group[0]).replace('ALIAS2',group[1]).replace('ALIAS3',group[2])\n",
    "        female_sent = sent4.replace('FEMALE_BIAS',i).replace('ALIAS1',group[0]).replace('ALIAS2',group[1]).replace('ALIAS3',group[2])\n",
    "        no_noise_female_bias['male_referent'].append(male_sent)\n",
    "        no_noise_female_bias['female_referent'].append(female_sent)\n",
    "        no_noise_female_bias['anaphor_type'].append('POS_PRON')\n",
    "        no_noise_female_bias['male_gold'].append('The '+i+',his')\n",
    "        no_noise_female_bias['female_gold'].append('The '+i+',her')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    }
   ],
   "source": [
    "no_noise_female_bias_df = pd.DataFrame.from_dict(no_noise_female_bias)\n",
    "bias = ['female']* len(no_noise_female_bias_df)\n",
    "no_noise_female_bias_df['gender_bias']=bias\n",
    "ambiguity = ['0'] * len(no_noise_female_bias_df)\n",
    "no_noise_female_bias_df['ambiguity']=ambiguity\n",
    "print(len(no_noise_female_bias_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John\n",
      "Mary\n",
      "('took', 'home', 'doctor')\n",
      "\n",
      "('brought', 'home', 'father')\n",
      "\n",
      "('took', 'home', 'friend')\n",
      "\n",
      "('introduced', 'left')\n",
      "\n",
      "('saw', 'went')\n",
      "\n",
      "('killed', 'disappeared')\n",
      "\n",
      "William\n",
      "Elizabeth\n",
      "('visited', 'I', 'father')\n",
      "\n",
      "('presents', 'II', 'regiment')\n",
      "\n",
      "('attacks', 'II', 'sword')\n",
      "\n",
      "('saves', 'disappears')\n",
      "\n",
      "('murders', 'dies')\n",
      "\n",
      "('stabbed', 'died')\n",
      "\n",
      "James\n",
      "Margaret\n",
      "('presented', 'Thatcher', 'coat')\n",
      "\n",
      "('presented', 'Thatcher', 'rose')\n",
      "\n",
      "('presented', 'Thatcher', 'letter')\n",
      "\n",
      "('thanked', 'went')\n",
      "\n",
      "('surprised', 'left')\n",
      "\n",
      "('photographed', 'left')\n",
      "\n",
      "David\n",
      "Sarah\n",
      "('sent', 'home', 'parents')\n",
      "\n",
      "('takes', 'home', 'brother')\n",
      "\n",
      "('drops', 'off', 'family')\n",
      "\n",
      "('grabs', 'leaves')\n",
      "\n",
      "('kisses', 'goes')\n",
      "\n",
      "('told', 'left')\n",
      "\n",
      "Robert\n",
      "Susan\n",
      "('took', 'home', 'children')\n",
      "\n",
      "('lets', 'play', 'cattle')\n",
      "\n",
      "('took', 'home', 'daughter')\n",
      "\n",
      "('stabbed', 'fled')\n",
      "\n",
      "('took', 'died')\n",
      "\n",
      "('helped', 'died')\n",
      "\n",
      "George\n",
      "Barbara\n",
      "('toured', 'Island', 'family')\n",
      "\n",
      "('visited', 'County', 'children')\n",
      "\n",
      "('toured', 'County', 'staff')\n",
      "\n",
      "('called', 'waited')\n",
      "\n",
      "('ate', 'left')\n",
      "\n",
      "('insulted', 'left')\n",
      "\n",
      "Charles\n",
      "Helen\n",
      "('visits', 'Keller', 'girlfriend')\n",
      "\n",
      "('visited', 'Keller', 'gift')\n",
      "\n",
      "('visited', 'Keller', 'sons')\n",
      "\n",
      "('confronted', 'left')\n",
      "\n",
      "('interviewed', 'left')\n",
      "\n",
      "('mentions', 'leaves')\n",
      "\n",
      "Michael\n",
      "Anne\n",
      "('killed', 'Rice', 'force')\n",
      "\n",
      "('killed', 'Rice', 'pistol')\n",
      "\n",
      "('shot', 'Rice', 'body')\n",
      "\n",
      "('saw', 'ran')\n",
      "\n",
      "('shot', 'collapsed')\n",
      "\n",
      "('punched', 'left')\n",
      "\n",
      "Richard\n",
      "Jane\n",
      "('holds', 'up', 'hand')\n",
      "\n",
      "('cut', 'open', 'knife')\n",
      "\n",
      "('took', 'home', 'dad')\n",
      "\n",
      "('found', 'disappeared')\n",
      "\n",
      "('handcuffed', 'disappeared')\n",
      "\n",
      "('helps', 'leaves')\n",
      "\n",
      "Thomas\n",
      "Ann\n",
      "('from', 'Arbor', 'lawyers')\n",
      "\n",
      "('in', 'Arbor', 'attorneys')\n",
      "\n",
      "('in', 'Arbor', 'dog')\n",
      "\n",
      "('tells', 'leaves')\n",
      "\n",
      "('released', 'left')\n",
      "\n",
      "('took', 'left')\n",
      "\n",
      "Paul\n",
      "Anna\n",
      "('takes', 'home', 'friends')\n",
      "\n",
      "('visited', 'Maria', 'relatives')\n",
      "\n",
      "('brings', 'home', 'family')\n",
      "\n",
      "('robbed', 'left')\n",
      "\n",
      "('kisses', 'dies')\n",
      "\n",
      "('kisses', 'disappears')\n",
      "\n",
      "Peter\n",
      "Jennifer\n",
      "('takes', 'home', 'mother')\n",
      "\n",
      "('brought', 'along', 'girlfriend')\n",
      "\n",
      "('brought', 'home', 'girlfriend')\n",
      "\n",
      "('kissed', 'leaves')\n",
      "\n",
      "('hurt', 'left')\n",
      "\n",
      "('stabbed', 'left')\n",
      "\n",
      "Joseph\n",
      "Alice\n",
      "('visited', 'Cooper', 'friends')\n",
      "\n",
      "('took', 'home', 'mother')\n",
      "\n",
      "('visits', 'Island', 'daughter')\n",
      "\n",
      "('confronts', 'dies')\n",
      "\n",
      "('killed', 'left')\n",
      "\n",
      "('grabs', 'disappears')\n",
      "\n",
      "Henry\n",
      "Ruth\n",
      "('escorted', 'out', 'money')\n",
      "\n",
      "('escorted', 'home', 'daughter')\n",
      "\n",
      "('took', 'out', 'son')\n",
      "\n",
      "('attacked', 'left')\n",
      "\n",
      "('called', 'came')\n",
      "\n",
      "('kissed', 'disappeared')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#case3\n",
    "sent1 = case3[0][0] #male referent  POS PRON\n",
    "sent2 = case3[0][1] #female referent  POS PRON\n",
    "sent3 = case3[1][0] #male referent PER PRON\n",
    "sent4 = case3[1][1] #female referent PER PRON\n",
    "for i, male_name, female_name in zip(male_bias, male_names, female_names):\n",
    "    print(male_name)\n",
    "    print(female_name)\n",
    "    #POS PRON\n",
    "    new_sent = sent1.replace('MALE_BIAS', i).replace('MALE_NAME',female_name) #we put female name temporarily to have better masked predictions\n",
    "    masked_sent = new_sent.replace('ALIAS1','{mask}').replace('ALIAS2','{mask}').replace('ALIAS3','{mask}')\n",
    "    alts = editor.suggest(masked_sent,remove_duplicates = True)[:100]\n",
    "    for group in alts:\n",
    "        doc = nlp(group[0])\n",
    "        for token in doc:\n",
    "            if token.pos_ != 'VERB':\n",
    "                break\n",
    "        alts.remove(group)\n",
    "        continue\n",
    "    random_nums = np.random.choice(len(alts),3)\n",
    "    for num in random_nums:\n",
    "        group = alts[num]\n",
    "        print(group)\n",
    "        print()\n",
    "        male_sent = sent1.replace('MALE_BIAS', i).replace('MALE_NAME',male_name).replace('ALIAS1',group[0]).replace('ALIAS2',group[1]).replace('ALIAS3',group[2])\n",
    "        female_sent = sent2.replace('MALE_BIAS',i).replace('FEMALE_NAME',female_name).replace('ALIAS1',group[0]).replace('ALIAS2',group[1]).replace('ALIAS3',group[2])\n",
    "        noise_male_bias['male_referent'].append(male_sent)\n",
    "        noise_male_bias['female_referent'].append(female_sent)\n",
    "        noise_male_bias['anaphor_type'].append('POS_PRON')\n",
    "        noise_male_bias['male_gold'].append('The '+i+',his')\n",
    "        noise_male_bias['female_gold'].append('The '+i+',her')\n",
    "    \n",
    "    #PER PRON \n",
    "    new_sent = sent3.replace('MALE_BIAS', i).replace('MALE_NAME',female_name) #we put female name temporarily to have better masked predictions\n",
    "    masked2_sent = new_sent.replace('ALIAS1','{mask}').replace('ALIAS2','{mask}')\n",
    "    alts = editor.suggest(masked2_sent,remove_duplicates = True)[:100]\n",
    "    for group in alts:\n",
    "        doc = nlp(group[0])\n",
    "        for token in doc:\n",
    "            if token.pos_ != 'VERB':\n",
    "                break\n",
    "        alts.remove(group)\n",
    "        continue\n",
    "    random_nums = np.random.choice(len(alts),3)\n",
    "    for num in random_nums:\n",
    "        group = alts[num]\n",
    "        print(group)\n",
    "        print()\n",
    "        male_sent = sent3.replace('MALE_BIAS', i).replace('MALE_NAME',male_name).replace('ALIAS1',group[0]).replace('ALIAS2',group[1])\n",
    "        female_sent = sent4.replace('MALE_BIAS',i).replace('FEMALE_NAME',female_name).replace('ALIAS1',group[0]).replace('ALIAS2',group[1])\n",
    "        noise_male_bias['male_referent'].append(male_sent)\n",
    "        noise_male_bias['female_referent'].append(female_sent)\n",
    "        noise_male_bias['anaphor_type'].append('PER_PRON')\n",
    "        noise_male_bias['male_gold'].append('The '+i+',he')\n",
    "        noise_male_bias['female_gold'].append('The '+i+',she')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    }
   ],
   "source": [
    "noise_male_bias_df = pd.DataFrame.from_dict(noise_male_bias)\n",
    "bias = ['male']* len(noise_male_bias_df)\n",
    "noise_male_bias_df['gender_bias']=bias\n",
    "ambiguity = ['1'] * len(noise_male_bias_df)\n",
    "noise_male_bias_df['ambiguity']=ambiguity\n",
    "print(len(noise_male_bias_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary\n",
      "John\n",
      "('said', 'lived', 'once')\n",
      "('said', 'stayed', 'parents')\n",
      "('said', 'lives', 'mother')\n",
      "('mentioned', 'left')\n",
      "('congratulated', 'disappeared')\n",
      "('was', 'left')\n",
      "Elizabeth\n",
      "William\n",
      "('let', 'stay', 'again')\n",
      "('took', 'home', 'mother')\n",
      "('let', 'stay', 'husband')\n",
      "('told', 'went')\n",
      "('left', 'left')\n",
      "('greeted', 'left')\n",
      "Margaret\n",
      "James\n",
      "('where', 'stayed', 'sister')\n",
      "('where', 'stays', 'parents')\n",
      "('took', 'home', 'mother')\n",
      "('arrested', 'left')\n",
      "('saved', 'disappeared')\n",
      "('loved', 'died')\n",
      "Sarah\n",
      "David\n",
      "('took', 'home', 'daughter')\n",
      "('held', 'up', 'hand')\n",
      "('picked', 'up', 'bags')\n",
      "('saw', 'died')\n",
      "('followed', 'left')\n",
      "('watched', 'left')\n",
      "Susan\n",
      "Robert\n",
      "('sends', 'home', 'friend')\n",
      "('held', 'tightly', 'own')\n",
      "('said', 'lived', 'family')\n",
      "('loved', 'died')\n",
      "('thanked', 'disappeared')\n",
      "('praised', 'left')\n",
      "Barbara\n",
      "George\n",
      "('visited', 'Washington', 'crew')\n",
      "('visited', 'Washington', 'uncle')\n",
      "('visited', 'Washington', 'dancers')\n",
      "('kissed', 'laughed')\n",
      "('passed', 'left')\n",
      "('showed', 'left')\n",
      "Helen\n",
      "Charles\n",
      "('credits', 'Manson', 'downfall')\n",
      "('visited', 'Darwin', 'daughter')\n",
      "('credits', 'Manson', 'transformation')\n",
      "('joined', 'left')\n",
      "('tells', 'dies')\n",
      "('thanked', 'sang')\n",
      "Anne\n",
      "Michael\n",
      "('let', 'stay', 'daughter')\n",
      "('sent', 'home', 'husband')\n",
      "('welcomes', 'back', 'smile')\n",
      "('distracted', 'left')\n",
      "('grabbed', 'vanished')\n",
      "('grabs', 'leaves')\n",
      "Jane\n",
      "Richard\n",
      "('says', 'was', 'today')\n",
      "('says', 'is', 'tonight')\n",
      "('that', 'took', 'home')\n",
      "('cheered', 'left')\n",
      "('hugs', 'runs')\n",
      "('grabs', 'leaves')\n",
      "Ann\n",
      "Thomas\n",
      "('picked', 'up', 'bicycle')\n",
      "('dropped', 'off', 'iPhone')\n",
      "('dropped', 'off', 'children')\n",
      "('dressed', 'left')\n",
      "('insulted', 'left')\n",
      "('took', 'disappeared')\n",
      "Anna\n",
      "Paul\n",
      "('says', 'lived', 'before')\n",
      "('let', 'stay', 'temporarily')\n",
      "('where', 'lived', 'wife')\n",
      "('attacked', 'left')\n",
      "('stopped', 'left')\n",
      "('greeted', 'left')\n",
      "Jennifer\n",
      "Peter\n",
      "('wore', 'Pan', 'jeans')\n",
      "('wears', 'Pan', 'skirt')\n",
      "('let', 'play', 'hands')\n",
      "('told', 'vanished')\n",
      "('told', 'died')\n",
      "('filmed', 'left')\n",
      "Alice\n",
      "Joseph\n",
      "('Tara', 'poses', 'clients')\n",
      "('Melissa', 'talks', 'clients')\n",
      "('Brittany', 'poses', 'clients')\n",
      "('removed', 'left')\n",
      "('summoned', 'vanished')\n",
      "('married', 'vanished')\n",
      "Ruth\n",
      "Henry\n",
      "('dropped', 'off', 'parents')\n",
      "('let', 'stay', 'son')\n",
      "('escorted', 'out', 'purse')\n",
      "('said', 'left')\n",
      "('thanked', 'folded')\n",
      "('bought', 'left')\n"
     ]
    }
   ],
   "source": [
    "#case4\n",
    "sent1 = case4[0][0] #male referent  POS PRON\n",
    "sent2 = case4[0][1] #female referent  POS PRON\n",
    "sent3 = case4[1][0] #male referent PER PRON\n",
    "sent4 = case4[1][1] #female referent PER PRON\n",
    "for i, female_name, male_name in zip(female_bias, female_names, male_names):\n",
    "    print(female_name)\n",
    "    print(male_name)\n",
    "    #POS PRON\n",
    "    new_sent = sent2.replace('FEMALE_BIAS', i).replace('FEMALE_NAME',male_name) #we put male name temporarily to have better masked predictions\n",
    "    masked_sent = new_sent.replace('ALIAS1','{mask}').replace('ALIAS2','{mask}').replace('ALIAS3','{mask}')\n",
    "    alts = editor.suggest(masked_sent,remove_duplicates = True)[:100]\n",
    "    for group in alts:\n",
    "        doc = nlp(group[0])\n",
    "        for token in doc:\n",
    "            if token.pos_ != 'VERB':\n",
    "                break\n",
    "        alts.remove(group)\n",
    "        continue\n",
    "    random_nums = np.random.choice(len(alts),3)\n",
    "    for num in random_nums:\n",
    "        group = alts[num]\n",
    "        print(group)\n",
    "        male_sent = sent1.replace('FEMALE_BIAS', i).replace('MALE_NAME',male_name).replace('ALIAS1',group[0]).replace('ALIAS2',group[1]).replace('ALIAS3',group[2])\n",
    "        female_sent = sent2.replace('FEMALE_BIAS',i).replace('FEMALE_NAME',female_name).replace('ALIAS1',group[0]).replace('ALIAS2',group[1]).replace('ALIAS3',group[2])\n",
    "        noise_female_bias['male_referent'].append(male_sent)\n",
    "        noise_female_bias['female_referent'].append(female_sent)\n",
    "        noise_female_bias['anaphor_type'].append('POS_PRON')\n",
    "        noise_female_bias['male_gold'].append('The '+i+',his')\n",
    "        noise_female_bias['female_gold'].append('The '+i+',her')\n",
    "    \n",
    "    #PER PRON \n",
    "    new_sent = sent4.replace('FEMALE_BIAS', i).replace('FEMALE_NAME',male_name) #we put female name temporarily to have better masked predictions\n",
    "    masked2_sent = new_sent.replace('ALIAS1','{mask}').replace('ALIAS2','{mask}')\n",
    "    alts = editor.suggest(masked2_sent,remove_duplicates = True)[:100]\n",
    "    for group in alts:\n",
    "        doc = nlp(group[0])\n",
    "        for token in doc:\n",
    "            if token.pos_ != 'VERB':\n",
    "                break\n",
    "        alts.remove(group)\n",
    "        continue\n",
    "    random_nums = np.random.choice(len(alts),3)\n",
    "    for num in random_nums:\n",
    "        group = alts[num]\n",
    "        print(group)\n",
    "        male_sent = sent3.replace('FEMALE_BIAS', i).replace('MALE_NAME',male_name).replace('ALIAS1',group[0]).replace('ALIAS2',group[1])\n",
    "        female_sent = sent4.replace('FEMALE_BIAS',i).replace('FEMALE_NAME',female_name).replace('ALIAS1',group[0]).replace('ALIAS2',group[1])\n",
    "        noise_female_bias['male_referent'].append(male_sent)\n",
    "        noise_female_bias['female_referent'].append(female_sent)\n",
    "        noise_female_bias['anaphor_type'].append('PER_PRON')\n",
    "        noise_female_bias['male_gold'].append('The '+i+',he')\n",
    "        noise_female_bias['female_gold'].append('The '+i+',she')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    }
   ],
   "source": [
    "noise_female_bias_df = pd.DataFrame.from_dict(noise_female_bias)\n",
    "bias = ['female']* len(noise_female_bias_df)\n",
    "noise_female_bias_df['gender_bias']=bias\n",
    "ambiguity = ['1'] * len(noise_female_bias_df)\n",
    "noise_female_bias_df['ambiguity']=ambiguity\n",
    "print(len(noise_female_bias_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/85/2p8b9qtx3zl0wyhyqxl6vn4h0000gn/T/ipykernel_93590/135831123.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  gender_bias_df = no_noise_male_bias_df.append(no_noise_female_bias_df)\n",
      "/var/folders/85/2p8b9qtx3zl0wyhyqxl6vn4h0000gn/T/ipykernel_93590/135831123.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  gender_bias_df = gender_bias_df.append(noise_male_bias_df)\n",
      "/var/folders/85/2p8b9qtx3zl0wyhyqxl6vn4h0000gn/T/ipykernel_93590/135831123.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  gender_bias_df = gender_bias_df.append(noise_female_bias_df)\n"
     ]
    }
   ],
   "source": [
    "gender_bias_df = no_noise_male_bias_df.append(no_noise_female_bias_df)\n",
    "gender_bias_df = gender_bias_df.append(noise_male_bias_df)\n",
    "gender_bias_df = gender_bias_df.append(noise_female_bias_df)\n",
    "\n",
    "path = '/Users/vicky/Desktop/Master/Period4/NLP/resit/data/gender_anaphortype_ambiguity.csv'\n",
    "\n",
    "gender_bias_df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_df = pd.read_csv(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('allennlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe63fdb75901ed9c5bae6586d4023f713527f36356cceecbfa8fb53c7b4de172"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

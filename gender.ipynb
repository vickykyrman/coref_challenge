{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import checklist\n",
    "from checklist.editor import Editor\n",
    "editor = Editor()\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "#np.random.seed(42)\n",
    "#random.seed(42)\n",
    "\n",
    "# #from wonderwords import RandomWord, RandomSentence\n",
    "# word_generator = RandomWord()\n",
    "# sent_generator = RandomSentence()\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_noise_male_bias = {'male_referent':[], 'female_referent':[], 'anaphor_type':[], 'male_gold':[], 'female_gold':[]}  #simple version\n",
    "no_noise_female_bias = {'male_referent':[], 'female_referent':[], 'anaphor_type':[], 'male_gold':[], 'female_gold':[]} #simple version\n",
    "\n",
    "noise_male_bias = {'male_referent':[], 'female_referent':[], 'anaphor_type':[], 'male_gold':[], 'female_gold':[]}  #extra pronoun disambiguation challenge (semantic capability)\n",
    "noise_female_bias = {'male_referent':[], 'female_referent':[], 'anaphor_type':[], 'male_gold':[], 'female_gold':[]} #extra disambiguation challenge\n",
    "#The firefighter saved the man with the support of his team\n",
    "#The firefighter saved the woman with the support of her team    #If it manages to solve the correference by also handling the ambiguity in the male (expected) version and it has to do so in the female version as well\n",
    "gender_bias_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#male bias - no noise\n",
    "case1 = [('The MALE_BIAS ALIAS1 ALIAS2, but he ALIAS3.', 'The MALE_BIAS ALIAS1 ALIAS2, but she ALIAS3.'), #personal pronoun\n",
    "        ('The MALE_BIAS ALIAS1, and his ALIAS2 ALIAS3.', 'The MALE_BIAS ALIAS1, and her ALIAS2 ALIAS3.')] #possessive pronoun\n",
    "#female bias - no noise\n",
    "case2 = [('The FEMALE_BIAS ALIAS1 ALIAS2, but he ALIAS3.', 'The FEMALE_BIAS ALIAS1 ALIAS2, but she ALIAS3.'), #personal pronoun \n",
    "        ('The FEMALE_BIAS ALIAS1 ALIAS2, and his ALIAS3.', 'The FEMALE_BIAS ALIAS1 ALIAS2, and her ALIAS3.')] #possessive pronoun\n",
    "\n",
    "#male bias - noise\n",
    "case3 = [('The MALE_BIAS ALIAS1 MALE_NAME ALIAS2 with his ALIAS3.', 'The MALE_BIAS ALIAS1 FEMALE_NAME ALIAS2 with her ALIAS3.'), #possessive pronoun\n",
    "        ('The MALE_BIAS ALIAS1 MALE_NAME, and then he ALIAS2.', 'The MALE_BIAS ALIAS1 FEMALE_NAME, and then she ALIAS2.')] #personal pronoun\n",
    "#female bias - noise\n",
    "case4 = [('The FEMALE_BIAS ALIAS1 MALE_NAME ALIAS2 with his ALIAS3.', 'The FEMALE_BIAS ALIAS1 FEMALE_NAME ALIAS2 with her ALIAS3.'), #possessive pronoun\n",
    "        ('The FEMALE_BIAS ALIAS1 MALE_NAME, and then he ALIAS2.', 'The FEMALE_BIAS ALIAS1 FEMALE_NAME, and then she ALIAS2.')] #personal pronoun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_bias = ['doctor','soldier','president','pilot','farmer','chef','professor','officer','firefighter','lawyer','athlete','football player','astronaut','manager']\n",
    "female_bias = ['hairdresser','secretary','nanny','nurse','teacher','dancer','singer','shop assistant','cheerleader','escort','house keeper','model','make-up artist','cashier']\n",
    "\n",
    "male_names = editor.lexicons['male'][:20]\n",
    "female_names = editor.lexicons['female'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#case1\n",
    "sent1 = case1[0][0] #male referent  PER PRON\n",
    "sent2 = case1[0][1] #female referent  PER PRON\n",
    "sent3 = case1[1][0] #male referent POS PRON\n",
    "sent4 = case1[1][1] #female referent POS PRON\n",
    "for i in male_bias:\n",
    "    new_sent = sent1.replace('MALE_BIAS',i)\n",
    "    #PER PRON\n",
    "    masked_sent = new_sent.replace('ALIAS1','{mask}').replace('ALIAS2','{mask}').replace('ALIAS3','{mask}')\n",
    "    alts = editor.suggest(masked_sent, remove_duplicates = True)[:100]\n",
    "    \n",
    "    for group in alts:\n",
    "        doc = nlp(group[0])\n",
    "        for token in doc:\n",
    "            print(token)\n",
    "            if token.pos_ != 'VERB':\n",
    "                break\n",
    "        alts.remove(group)\n",
    "        continue\n",
    "    random_nums = np.random.choice(len(alts),3)\n",
    "    for num in random_nums:\n",
    "        group = alts[num]\n",
    "        print(group)\n",
    "        male_sent = sent1.replace('MALE_BIAS',i).replace('ALIAS1',group[0]).replace('ALIAS2',group[1]).replace('ALIAS3',group[2])\n",
    "        female_sent = sent2.replace('MALE_BIAS',i).replace('ALIAS1',group[0]).replace('ALIAS2',group[1]).replace('ALIAS3',group[2])\n",
    "        no_noise_male_bias['male_referent'].append(male_sent)\n",
    "        no_noise_male_bias['female_referent'].append(female_sent)\n",
    "        no_noise_male_bias['anaphor_type'].append('PER_PRON')\n",
    "        no_noise_male_bias['male_gold'].append('The '+i+',he')\n",
    "        no_noise_male_bias['female_gold'].append('The '+i+',she')\n",
    "    \n",
    "    #POS PRON\n",
    "    new_sent = sent3.replace('MALE_BIAS',i)\n",
    "    masked2_sent = new_sent.replace('ALIAS1','{mask}').replace('ALIAS2','{mask}').replace('ALIAS3','{mask}')\n",
    "    alts = editor.suggest(masked2_sent, remove_duplicates = True)[:100]\n",
    "    for group in alts:\n",
    "        doc = nlp(group[0])\n",
    "        for token in doc:\n",
    "            if token.pos_ != 'VERB':\n",
    "                break\n",
    "        alts.remove(group)\n",
    "        continue\n",
    "    \n",
    "    random_nums = np.random.choice(len(alts),3)\n",
    "    for num in random_nums:\n",
    "        group = alts[num]\n",
    "        male_sent = sent3.replace('MALE_BIAS',i).replace('ALIAS1',group[0]).replace('ALIAS2',group[1]).replace('ALIAS3',group[2])\n",
    "        female_sent = sent4.replace('MALE_BIAS',i).replace('ALIAS1',group[0]).replace('ALIAS2',group[1]).replace('ALIAS3',group[2])\n",
    "        no_noise_male_bias['male_referent'].append(male_sent)\n",
    "        no_noise_male_bias['female_referent'].append(female_sent)\n",
    "        no_noise_male_bias['anaphor_type'].append('POS_PRON')\n",
    "        no_noise_male_bias['male_gold'].append('The '+i+',his')\n",
    "        no_noise_male_bias['female_gold'].append('The '+i+',her')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_noise_male_bias_df = pd.DataFrame.from_dict(no_noise_male_bias)\n",
    "bias = ['male']* len(no_noise_male_bias_df)\n",
    "no_noise_male_bias_df['gender_bias']=bias\n",
    "ambiguity = ['0'] * len(no_noise_male_bias_df)\n",
    "no_noise_male_bias_df['ambiguity']=ambiguity\n",
    "len(no_noise_male_bias_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#case2\n",
    "sent1 = case2[0][0] #male referent  PER PRON\n",
    "sent2 = case2[0][1] #female referent  PER PRON\n",
    "sent3 = case2[1][0] #male referent POS PRON\n",
    "sent4 = case2[1][1] #female referent POS PRON\n",
    "for i in female_bias:\n",
    "    #PER PRON\n",
    "    new_sent = sent1.replace('MALE_BIAS',i)\n",
    "    masked_sent = new_sent.replace('ALIAS1','{mask}').replace('ALIAS2','{mask}').replace('ALIAS3','{mask}')\n",
    "    alts = editor.suggest(masked_sent, remove_duplicates = True)[:100]\n",
    "    for group in alts:\n",
    "        doc = nlp(group[0])\n",
    "        for token in doc:\n",
    "            if token.pos_ != 'VERB':\n",
    "                break\n",
    "        alts.remove(group)\n",
    "        continue\n",
    "    random_nums = np.random.choice(len(alts),3)\n",
    "    for num in random_nums:\n",
    "        group = alts[num]\n",
    "        male_sent = sent1.replace('FEMALE_BIAS',i).replace('ALIAS1',group[0]).replace('ALIAS2',group[1]).replace('ALIAS3',group[2])\n",
    "        female_sent = sent2.replace('FEMALE_BIAS',i).replace('ALIAS1',group[0]).replace('ALIAS2',group[1]).replace('ALIAS3',group[2])\n",
    "        no_noise_female_bias['male_referent'].append(male_sent)\n",
    "        no_noise_female_bias['female_referent'].append(female_sent)\n",
    "        no_noise_female_bias['anaphor_type'].append('PER_PRON')\n",
    "        no_noise_female_bias['male_gold'].append('The '+i+',he')\n",
    "        no_noise_female_bias['female_gold'].append('The '+i+',she')\n",
    "    \n",
    "    #POS PRON\n",
    "    new_sent = sent3.replace('MALE_BIAS',i)\n",
    "    masked2_sent = new_sent.replace('ALIAS1','{mask}').replace('ALIAS2','{mask}').replace('ALIAS3','{mask}')\n",
    "    alts = editor.suggest(masked2_sent, remove_duplicates = True)[:100]\n",
    "    for group in alts:\n",
    "        doc = nlp(group[0])\n",
    "        for token in doc:\n",
    "            if token.pos_ != 'VERB':\n",
    "                break\n",
    "        alts.remove(group)\n",
    "        continue\n",
    "    random_nums = np.random.choice(len(alts),3)\n",
    "    for num in random_nums:\n",
    "        group = alts[num]\n",
    "        male_sent = sent3.replace('FEMALE_BIAS',i).replace('ALIAS1',group[0]).replace('ALIAS2',group[1]).replace('ALIAS3',group[2])\n",
    "        female_sent = sent4.replace('FEMALE_BIAS',i).replace('ALIAS1',group[0]).replace('ALIAS2',group[1]).replace('ALIAS3',group[2])\n",
    "        no_noise_female_bias['male_referent'].append(male_sent)\n",
    "        no_noise_female_bias['female_referent'].append(female_sent)\n",
    "        no_noise_female_bias['anaphor_type'].append('POS_PRON')\n",
    "        no_noise_female_bias['male_gold'].append('The '+i+',his')\n",
    "        no_noise_female_bias['female_gold'].append('The '+i+',her')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_noise_female_bias_df = pd.DataFrame.from_dict(no_noise_female_bias)\n",
    "bias = ['female']* len(no_noise_female_bias_df)\n",
    "no_noise_female_bias_df['gender_bias']=bias\n",
    "ambiguity = ['0'] * len(no_noise_female_bias_df)\n",
    "no_noise_female_bias_df['ambiguity']=ambiguity\n",
    "print(len(no_noise_female_bias_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#case3\n",
    "sent1 = case3[0][0] #male referent  POS PRON\n",
    "sent2 = case3[0][1] #female referent  POS PRON\n",
    "sent3 = case3[1][0] #male referent PER PRON\n",
    "sent4 = case3[1][1] #female referent PER PRON\n",
    "for i, male_name, female_name in zip(male_bias, male_names, female_names):\n",
    "    print(male_name)\n",
    "    print(female_name)\n",
    "    #POS PRON\n",
    "    new_sent = sent1.replace('MALE_BIAS', i).replace('MALE_NAME',female_name) #we put female name temporarily to have better masked predictions\n",
    "    masked_sent = new_sent.replace('ALIAS1','{mask}').replace('ALIAS2','{mask}').replace('ALIAS3','{mask}')\n",
    "    alts = editor.suggest(masked_sent,remove_duplicates = True)[:100]\n",
    "    for group in alts:\n",
    "        doc = nlp(group[0])\n",
    "        for token in doc:\n",
    "            if token.pos_ != 'VERB':\n",
    "                break\n",
    "        alts.remove(group)\n",
    "        continue\n",
    "    random_nums = np.random.choice(len(alts),3)\n",
    "    for num in random_nums:\n",
    "        group = alts[num]\n",
    "        print(group)\n",
    "        print()\n",
    "        male_sent = sent1.replace('MALE_BIAS', i).replace('MALE_NAME',male_name).replace('ALIAS1',group[0]).replace('ALIAS2',group[1]).replace('ALIAS3',group[2])\n",
    "        female_sent = sent2.replace('MALE_BIAS',i).replace('FEMALE_NAME',female_name).replace('ALIAS1',group[0]).replace('ALIAS2',group[1]).replace('ALIAS3',group[2])\n",
    "        noise_male_bias['male_referent'].append(male_sent)\n",
    "        noise_male_bias['female_referent'].append(female_sent)\n",
    "        noise_male_bias['anaphor_type'].append('POS_PRON')\n",
    "        noise_male_bias['male_gold'].append('The '+i+',his')\n",
    "        noise_male_bias['female_gold'].append('The '+i+',her')\n",
    "    \n",
    "    #PER PRON \n",
    "    new_sent = sent3.replace('MALE_BIAS', i).replace('MALE_NAME',female_name) #we put female name temporarily to have better masked predictions\n",
    "    masked2_sent = new_sent.replace('ALIAS1','{mask}').replace('ALIAS2','{mask}')\n",
    "    alts = editor.suggest(masked2_sent,remove_duplicates = True)[:100]\n",
    "    for group in alts:\n",
    "        doc = nlp(group[0])\n",
    "        for token in doc:\n",
    "            if token.pos_ != 'VERB':\n",
    "                break\n",
    "        alts.remove(group)\n",
    "        continue\n",
    "    random_nums = np.random.choice(len(alts),3)\n",
    "    for num in random_nums:\n",
    "        group = alts[num]\n",
    "        print(group)\n",
    "        print()\n",
    "        male_sent = sent3.replace('MALE_BIAS', i).replace('MALE_NAME',male_name).replace('ALIAS1',group[0]).replace('ALIAS2',group[1])\n",
    "        female_sent = sent4.replace('MALE_BIAS',i).replace('FEMALE_NAME',female_name).replace('ALIAS1',group[0]).replace('ALIAS2',group[1])\n",
    "        noise_male_bias['male_referent'].append(male_sent)\n",
    "        noise_male_bias['female_referent'].append(female_sent)\n",
    "        noise_male_bias['anaphor_type'].append('PER_PRON')\n",
    "        noise_male_bias['male_gold'].append('The '+i+',he')\n",
    "        noise_male_bias['female_gold'].append('The '+i+',she')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_male_bias_df = pd.DataFrame.from_dict(noise_male_bias)\n",
    "bias = ['male']* len(noise_male_bias_df)\n",
    "noise_male_bias_df['gender_bias']=bias\n",
    "ambiguity = ['1'] * len(noise_male_bias_df)\n",
    "noise_male_bias_df['ambiguity']=ambiguity\n",
    "print(len(noise_male_bias_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#case4\n",
    "sent1 = case4[0][0] #male referent  POS PRON\n",
    "sent2 = case4[0][1] #female referent  POS PRON\n",
    "sent3 = case4[1][0] #male referent PER PRON\n",
    "sent4 = case4[1][1] #female referent PER PRON\n",
    "for i, female_name, male_name in zip(female_bias, female_names, male_names):\n",
    "    print(female_name)\n",
    "    print(male_name)\n",
    "    #POS PRON\n",
    "    new_sent = sent2.replace('FEMALE_BIAS', i).replace('FEMALE_NAME',male_name) #we put male name temporarily to have better masked predictions\n",
    "    masked_sent = new_sent.replace('ALIAS1','{mask}').replace('ALIAS2','{mask}').replace('ALIAS3','{mask}')\n",
    "    alts = editor.suggest(masked_sent,remove_duplicates = True)[:100]\n",
    "    for group in alts:\n",
    "        doc = nlp(group[0])\n",
    "        for token in doc:\n",
    "            if token.pos_ != 'VERB':\n",
    "                break\n",
    "        alts.remove(group)\n",
    "        continue\n",
    "    random_nums = np.random.choice(len(alts),3)\n",
    "    for num in random_nums:\n",
    "        group = alts[num]\n",
    "        print(group)\n",
    "        male_sent = sent1.replace('FEMALE_BIAS', i).replace('MALE_NAME',male_name).replace('ALIAS1',group[0]).replace('ALIAS2',group[1]).replace('ALIAS3',group[2])\n",
    "        female_sent = sent2.replace('FEMALE_BIAS',i).replace('FEMALE_NAME',female_name).replace('ALIAS1',group[0]).replace('ALIAS2',group[1]).replace('ALIAS3',group[2])\n",
    "        noise_female_bias['male_referent'].append(male_sent)\n",
    "        noise_female_bias['female_referent'].append(female_sent)\n",
    "        noise_female_bias['anaphor_type'].append('POS_PRON')\n",
    "        noise_female_bias['male_gold'].append('The '+i+',his')\n",
    "        noise_female_bias['female_gold'].append('The '+i+',her')\n",
    "    \n",
    "    #PER PRON \n",
    "    new_sent = sent4.replace('FEMALE_BIAS', i).replace('FEMALE_NAME',male_name) #we put female name temporarily to have better masked predictions\n",
    "    masked2_sent = new_sent.replace('ALIAS1','{mask}').replace('ALIAS2','{mask}')\n",
    "    alts = editor.suggest(masked2_sent,remove_duplicates = True)[:100]\n",
    "    for group in alts:\n",
    "        doc = nlp(group[0])\n",
    "        for token in doc:\n",
    "            if token.pos_ != 'VERB':\n",
    "                break\n",
    "        alts.remove(group)\n",
    "        continue\n",
    "    random_nums = np.random.choice(len(alts),3)\n",
    "    for num in random_nums:\n",
    "        group = alts[num]\n",
    "        print(group)\n",
    "        male_sent = sent3.replace('FEMALE_BIAS', i).replace('MALE_NAME',male_name).replace('ALIAS1',group[0]).replace('ALIAS2',group[1])\n",
    "        female_sent = sent4.replace('FEMALE_BIAS',i).replace('FEMALE_NAME',female_name).replace('ALIAS1',group[0]).replace('ALIAS2',group[1])\n",
    "        noise_female_bias['male_referent'].append(male_sent)\n",
    "        noise_female_bias['female_referent'].append(female_sent)\n",
    "        noise_female_bias['anaphor_type'].append('PER_PRON')\n",
    "        noise_female_bias['male_gold'].append('The '+i+',he')\n",
    "        noise_female_bias['female_gold'].append('The '+i+',she')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_female_bias_df = pd.DataFrame.from_dict(noise_female_bias)\n",
    "bias = ['female']* len(noise_female_bias_df)\n",
    "noise_female_bias_df['gender_bias']=bias\n",
    "ambiguity = ['1'] * len(noise_female_bias_df)\n",
    "noise_female_bias_df['ambiguity']=ambiguity\n",
    "print(len(noise_female_bias_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_bias_df = no_noise_male_bias_df.append(no_noise_female_bias_df)\n",
    "gender_bias_df = gender_bias_df.append(noise_male_bias_df)\n",
    "gender_bias_df = gender_bias_df.append(noise_female_bias_df)\n",
    "\n",
    "path = '../data/gender_anaphortype_ambiguity.csv'\n",
    "\n",
    "gender_bias_df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_df = pd.read_csv(path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('allennlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe63fdb75901ed9c5bae6586d4023f713527f36356cceecbfa8fb53c7b4de172"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
